# How does this program work
## About the suggested fature
Further Considerations:
1. Could consider what to do if a process dies and would prefer to resume at the current
   processing position on restart.
   1. Rabbit mq will secure save and store the content of the queue in local file, and restore it when it is runned again
2. Could consider how to persist data that has not been normalized.
   1. The data not been normalized is securely store in the rabbit mq queue, and will not loss
3. Could consider various methods of interprocess communication between the raw process
   and the normalizer process (e.g. shared memory, pipes, and websocket).
   1. The inter process communication is most automatically handle by rabbitmq, but I do do several things to make sure it is squential
      1. 1: There is an ACK and NACK between producer and consumer, it will guratee the transcation between producer and consumer will definitely happen
      1. Even if one of them producer or consumer failed, rabbitmq will automatically restore entire transaction by redo the job again
```agsl
           // Producer
           Channel channel = connection.createChannel()) {

            // Declare a durable exchange
            channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT, true);

            // Declare a durable queue
            channel.queueDeclare(QUEUE_NAME, true, false, false, null);

            // Bind the queue to the exchange
            channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "");

            AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder()
                    .deliveryMode(2) // Make message persistent
                    .headers(Collections.singletonMap("sequence", this.counter.get().longValue()))
                    .build();

            data = data + "," + this.counter.getAndIncrement().toString();

            channel.basicPublish(EXCHANGE_NAME, "", properties, data.getBytes(StandardCharsets.UTF_8));
            System.out.println("Produced: " + data);
            
            //------------------------------------
            // Consumer

            // Set QoS to 1 to ensure sequential processing
            channel.basicQos(1);

            System.out.println(" [*] Waiting for messages. To exit press CTRL+C");

            DeliverCallback deliverCallback = (consumerTag, delivery) -> {
                String message = new String(delivery.getBody(), StandardCharsets.UTF_8);
                try {
                    System.out.println(" [x] Received '" + message + "', start to persistence");
                    this.dataPersistance(message);
                    channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);
                } catch (Exception e) {
                    System.err.println("Error processing message: " + e.getMessage());
                    channel.basicNack(delivery.getEnvelope().getDeliveryTag(), false, true);
                }
            };

            channel.basicConsume(QUEUE_NAME, false, deliverCallback, consumerTag -> { });
```
4. Could consider optimizing the serialization format if time permits.
   1. I optimize the serialization format by storing it in a local SQL database, leveraging SQLite3
      1. It can guarantee the ACID property, and it is recoverable
      2. It is lightweight and more readable
      3. It is compatible with most companies' requirements
         3. I do think this is a bad idea though
## How does it work in simple words
* Basically, a bunch of producers are reading from the websocket, and a bunch of consumers read the contexts that are generated by the producer.
* The consumers read the content sequentially; after the consumer finishes consuming, it says ACK, anything wrong it says NACK
* After the producer hears the response, the transaction is done, and it will keep listening.
* Ideally, the number of producers can be arbitrary, but the number of consumers shall be one since SQLite3 is default in single-thread mode. Otherwise, it makes no sense since the API of the website is not very fast.

## Tech Stack explained
* RabbitMQ
   * A high-performance consumer and producer library
   * Why
      * Because it is easy to use, implement, provides a bunch of useful functions
* SQLite
   * A high-performance lightweight SQL database

## Deal with edge cases
* 1. What if both threads return the same value
   * There is a cache, built by concurrent map
   * Every consumer that tries to insert data into the database will be checked by the cache
* 2. Will the cache be too big
   * The map is cleaned at certain times
   * It is a constant in NovaConstant.java
* 3. Is the process of data maintained in order
   * Yes it is, read this ðŸ‘‡
```
Section 4.7 of the AMQP 0-9-1 core specification explains the conditions under which ordering is guaranteed: messages published in one channel, passing through one exchange and one queue and one outgoing channel will be received in the same order that they were sent. RabbitMQ offers stronger guarantees since release 2.7.0.

Messages can be returned to the queue using AMQP methods that feature a requeue parameter (basic.recover, basic.reject and basic.nack), or due to a channel closing while holding unacknowledged messages. Any of these scenarios caused messages to be requeued at the back of the queue for RabbitMQ releases earlier than 2.7.0. From RabbitMQ release 2.7.0, messages are always held in the queue in publication order, even in the presence of requeueing or channel closure. (emphasis added)
```
## Potential issues
* Some of the packages used in this project are not MIT licensed, be careful when using them
* The performance of the program does not increase linearly with the number of consumers, since the physical CPU does not have an infinite number of cores and Coinbase is slow!